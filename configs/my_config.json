{
  "model": {
    "vocab_size": 50257,
    "hidden_dim": 768,
    "num_layers": 12,
    "num_heads": 12,
    "dropout": 0.1,
    "max_seq_length": 1024,
    "primes": [
      23,
      29,
      31,
      37,
      41,
      43,
      47
    ],
    "max_iterations": 10,
    "entropy_threshold": 0.01,
    "phase_factor": 0.5,
    "extensions": {},
    "extra_model_params": {}
  },
  "training": {
    "batch_size": 4,
    "eval_batch_size": 16,
    "learning_rate": 5e-05,
    "weight_decay": 0.01,
    "max_epochs": 1,
    "training_type": "dialogue",
    "learning_mode": "adaptive",
    "device": null,
    "use_mixed_precision": true,
    "optimizer": "adamw",
    "max_grad_norm": 1.0,
    "accumulation_steps": 1,
    "lr_scheduler": "cosine",
    "warmup_steps": 0,
    "logging_steps": 10,
    "save_steps": 0,
    "eval_steps": 0,
    "save_every_epoch": true,
    "disable_optimizer_saving": false,
    "output_dir": "runs/quantum_resonance",
    "seed": 42,
    "extra_training_params": {}
  },
  "data": {
    "dataset_name": "daily_dialog",
    "dataset_variant": "wikitext-103-v1",
    "tokenizer_name": "gpt2",
    "train_file": null,
    "validation_file": null,
    "test_file": null,
    "data_path": null,
    "max_length": 512,
    "stride": 256,
    "preprocessing_num_workers": 4,
    "cache_dir": ".cache",
    "return_tensors": "pt",
    "subset_size": null,
    "system_prompt": "",
    "function_defs_path": null,
    "extra_data_params": {}
  }
}